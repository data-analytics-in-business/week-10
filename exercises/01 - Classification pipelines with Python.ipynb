{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f293ebfe",
   "metadata": {},
   "source": [
    "# 01 - Classification pipelines in Python\n",
    "We are going to use some of the things we learned in the previous notebook, but develop them in a more robust and re-useable way by introducing the concept of \"pipelines\" (just think of \"data in\" and \"predictions out\"). Additionally, we are going to explore how to evaluate and compare classification pipelines using the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbae8df",
   "metadata": {},
   "source": [
    "## Import dataset\n",
    "Let's import the same dataset from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb33e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/Lasagna Triers Logistic Regression.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc6bc6",
   "metadata": {},
   "source": [
    "Let's specify out attribute/predictor variables $X$ and the target variable $y$ that we wish to predict.\n",
    "\n",
    "Note: To create $X$, we drop the ID and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42710694",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Person','Have Tried'])\n",
    "y = df['Have Tried']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adec821",
   "metadata": {},
   "source": [
    "## Pre-process dataset\n",
    "To start to create a pipeline, we need to consider how we will pre-process the data. As was seen in the previous notebook, different data types are processed in different ways.\n",
    "\n",
    "Run the code below to show the data-types of each solumn in $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6fdbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7624bbdc",
   "metadata": {},
   "source": [
    "We can consider the columns of type `int64` to be numerical and the columns of type `object` to e categorical.\n",
    "\n",
    "Run the following code to select the columns containing numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b580d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X.select_dtypes(include=['int64'])\n",
    "X_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efbcae1",
   "metadata": {},
   "source": [
    "Run the following code to select the columns containing categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754764d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = X.select_dtypes(include=['object'])\n",
    "X_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9670c3",
   "metadata": {},
   "source": [
    "In the previous notebook we used the `get_dummies` method to encode the categorical variables in a form that can be used in logistic regression. Here, we will do the same thing, but we will use the `OneHotEncoder` from the `sklearn` package.\n",
    "\n",
    "Run the code below to see what the `OneHotEncoder` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f7bb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "hot_encoder = OneHotEncoder(drop='first', handle_unknown=\"ignore\", sparse=False)\n",
    "hot_encoder.fit(X_cat)\n",
    "X_cat_onehot = pd.DataFrame(hot_encoder.transform(X_cat), \n",
    "                                  columns=hot_encoder.get_feature_names_out(X_cat.columns))\n",
    "X_cat_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d2b802",
   "metadata": {},
   "source": [
    "Note that we have dropped the first value from each categorical variable (remember liner dependency?), and we have told our `OneHotEncoder` instance to ignore any values it seens in the future which are unknow to it.\n",
    "\n",
    "We are also going to scale the numeric variables to be more similar in values to the coded categorical values. To do this, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7606cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_num_scaled = pd.DataFrame(minmax_scaler.fit_transform(X_num), columns=X_num.columns)\n",
    "X_num_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07407721",
   "metadata": {},
   "source": [
    " Finally, let's join the processed columns back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72824d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = pd.concat([X_num_scaled, X_cat_onehot], axis=1)\n",
    "X_train_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7958b8",
   "metadata": {},
   "source": [
    "## Let's create a pipeline\n",
    "Now, all the above pre-processing steps can be included in a pipeline, which can then be used to process new data, in the same way, without re-writing all the code again.\n",
    "\n",
    "To create our first pipeline, please run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a custom pipeline\n",
    "class PreprocessingPipeline():\n",
    "    def __init__(self):\n",
    "        # Initialise the encoder and scaler\n",
    "        self.hot_encoder = OneHotEncoder(drop='first', handle_unknown=\"ignore\", sparse=False)\n",
    "        self.minmax_scaler = MinMaxScaler()\n",
    "        \n",
    "        # Prepare to store the column names\n",
    "        self.scaled_columns = []\n",
    "        self.coded_columns = []\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # Split X into object/categorical and int64/numeric columns\n",
    "        X_cat, X_num = self._split_dtypes(X)\n",
    "        \n",
    "        # Fit the encoder to object/categorical data \n",
    "        self.hot_encoder.fit(X_cat)\n",
    "        self.coded_columns = self.hot_encoder.get_feature_names_out(X_cat.columns)\n",
    "        \n",
    "        # Fit the scaler to int64/numeric data\n",
    "        self.minmax_scaler.fit(X_num)\n",
    "        self.scaled_columns = X_num.columns\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        # Split X into object/categorical and int64/numeric columns\n",
    "        X_cat, X_num = self._split_dtypes(X)\n",
    "        \n",
    "        #Transform the object/categorical data \n",
    "        X_cat_out = pd.DataFrame(self.hot_encoder.transform(X_cat),columns=self.coded_columns)\n",
    "        \n",
    "        #Transform the int64/numeric data\n",
    "        X_num_out = pd.DataFrame(minmax_scaler.fit_transform(X_num),columns=self.scaled_columns)\n",
    "        \n",
    "        # Return the full processed data-frame\n",
    "        return pd.concat([X_num_out, X_cat_out], axis=1)\n",
    "    \n",
    "    def _split_dtypes(self, X):\n",
    "        return(X.select_dtypes(include=['object']),X.select_dtypes(include=['int64']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93953f8",
   "metadata": {},
   "source": [
    "We can now fit the pre-processing pipeline to out input data $X$, and use it to transform our input data $X$.\n",
    "\n",
    "To do this, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipe = PreprocessingPipeline()\n",
    "my_pipe.fit(X)\n",
    "my_pipe.transform(X).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34775931",
   "metadata": {},
   "source": [
    "Look the same as before?\n",
    "\n",
    "Great, BUT we can also pass *new* data through the pipeline.\n",
    "\n",
    "Let's importh the `New_Customers.csv` from the previous notebook, and create an `X_new`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('../data/New_Customers.csv')\n",
    "X_new = df_new.drop(columns=['New_Person'])\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442a5a97",
   "metadata": {},
   "source": [
    "Now let's pass the new data through our existing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b5325",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipe.transform(X_new).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f1891",
   "metadata": {},
   "source": [
    "It works!?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1099fe",
   "metadata": {},
   "source": [
    "## Let's create a classification pipeline\n",
    "Our pre-processing pipeline is great, but we actually want to classify examples at the end of it. \n",
    "\n",
    "Well, we can easily extend our pre-processing pipeline to become a classification pipeline.\n",
    "\n",
    "Run the code below to do exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_pipeline = Pipeline([\n",
    "    ('preprocessor', PreprocessingPipeline()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd647b4",
   "metadata": {},
   "source": [
    "Now let's use our classificiation pipeline to create some predictions for our new customers.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline.fit(X,y)\n",
    "df_new['Have Tried'] = clf_pipeline.predict(X_new)\n",
    "df_new.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c13d29",
   "metadata": {},
   "source": [
    "Looks good? But how do we know if our classification pipeline is performing well? Let's explore below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d5714",
   "metadata": {},
   "source": [
    "## Let's evaluate our classification pipeline\n",
    "As in the previous notebook, we can view the confusion matrix of our classification pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(clf_pipeline, X, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ecb805",
   "metadata": {},
   "source": [
    "We see True Negatives (TN) of 289, False Negatives (FN) of 74, False Positives (FP) of 72, and True Positives (TP) of 421.\n",
    "\n",
    "There are several ways we can use the values in the confusion matrix to arrive to a single performance metric. Let's import some now and define our true and predicted labels.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "y_true = y.values\n",
    "y_pred = clf_pipeline.predict(X)\n",
    "\n",
    "A = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy = (TP + TN) /(TP + FP + FN + TN) = {A:.4f}')\n",
    "\n",
    "P = precision_score(y_true, y_pred, pos_label='Yes')\n",
    "print(f'Precision = TP / (TP + FP) = {P:.4f}')\n",
    "\n",
    "R = recall_score(y_true, y_pred, pos_label='Yes')\n",
    "print(f'Recall = TP / (TP + FN) = {R:.4f}')\n",
    "\n",
    "F1 = f1_score(y_true, y_pred, pos_label='Yes')\n",
    "print(f'F1 Score = 2 * (P * R) / (P + R) = {F1:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207863e8",
   "metadata": {},
   "source": [
    "## Let's estimate test performance\n",
    "That's all great, but what we care about is model performance on new, unseen data. How can we estimate that?\n",
    "\n",
    "One way, is through *training* and *testing*.\n",
    "\n",
    "Let's split our $X$ and $y$ data into training and test datasets, then fit our classification pipeline to the training data and test it on the test data.\n",
    "\n",
    "Run the code below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5c94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "clf_pipeline = Pipeline([\n",
    "    ('preprocessor', PreprocessingPipeline()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "clf_pipeline.fit(X_train, y_train)\n",
    "ConfusionMatrixDisplay.from_estimator(clf_pipeline, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ebac14",
   "metadata": {},
   "source": [
    "And there you have, it. We have:\n",
    "1. Created a pre-processing pipeline\n",
    "2. Extended the pre-processing pipeline to create a classification pipeline\n",
    "3. Used training data to fit the classification pipelin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa68086e",
   "metadata": {},
   "source": [
    "### Task - Variation over training testing splits\n",
    "Run the above code a few times to get a feel for how the results change for different training and test splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfc3833",
   "metadata": {},
   "source": [
    "### Task - Compute scores on test set\n",
    "Calculate the Accuracy, Precision, Recall, and F1 Score of the classification pipeline (`clf_pipeline`) on the test set (`X_test`, `y_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56752521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (SOLUTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50172092",
   "metadata": {},
   "source": [
    "### Task - Compare Logistic Regression to Decision Tree Classifier\n",
    "Import the `DecisionTreeClassifier`, create a `LogisticRegression` pipeline and `DecisionTreeClassifier` pipeline, fit both pipeline to the same training data, and show the confusion matrix for each pipeline tested on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# (SOLUTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365ecfa1",
   "metadata": {},
   "source": [
    "### Task - Final\n",
    "Compute Accuracy, Precision, Recall, and F1 Score for both pipelines and identify which pipeline performs best for each score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (SOLUTION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
